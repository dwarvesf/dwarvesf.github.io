<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Reinforcement-Learning on Dwarves Foundation</title><link>https://memo.d.foundation/tags/reinforcement-learning/</link><description>Recent content in Reinforcement-Learning on Dwarves Foundation</description><generator>Hugo</generator><language>en-us</language><managingEditor>han@d.foundation (Han Ngo)</managingEditor><webMaster>han@d.foundation (Han Ngo)</webMaster><copyright>Â© 2024 Dwarves Foundation.</copyright><lastBuildDate>Wed, 03 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://memo.d.foundation/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Proximal Policy Optimization</title><link>https://memo.d.foundation/playground/ai/proximal-policy-optimization/</link><pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/proximal-policy-optimization/</guid><description>Introduction Proximal Policy Optimization (PPO) is an algorithm that aims to improve the stability of training by avoiding overly large policy updates.</description></item></channel></rss>